// scripts/csvImportHelpers.ts
import { join } from 'path';
import { path } from 'app-root-path';
import fs from 'fs';
import Papa from 'papaparse';
import { Weather, WeatherCreationAttributes } from '../service-init/models/main/weather';
import { logger } from '../shared/configs/logger.config';

/**
 * CSV íŒŒì¼ì„ ì—¬ëŸ¬ ê²½ë¡œì—ì„œ ì°¾ëŠ” í•¨ìˆ˜
 */
export function findCsvFile(filename: string): string {
  // Docker í™˜ê²½ì¸ì§€ í™•ì¸ - process.env.DOCKER_ENVê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ Docker í™˜ê²½ìœ¼ë¡œ ê°„ì£¼
  const isDocker = process.env.DOCKER_ENV === 'true' || fs.existsSync('/.dockerenv');
  
  // Docker í™˜ê²½ì¼ ë•Œ ë” ì •í™•í•œ ê²½ë¡œë¥¼ ë¨¼ì € ì‹œë„
  if (isDocker) {
    logger.info('Docker í™˜ê²½ì—ì„œ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤.');
    // Docker ì»¨í…Œì´ë„ˆ ë‚´ ê²½ë¡œë“¤
    const dockerPaths = [
      '/app/dist/' + filename,  // Docker ì»¨í…Œì´ë„ˆ ë‚´ dist ë””ë ‰í† ë¦¬
      '/app/' + filename,       // Docker ì»¨í…Œì´ë„ˆ ë‚´ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
      '/app/src/' + filename    // Docker ì»¨í…Œì´ë„ˆ ë‚´ src ë””ë ‰í† ë¦¬
    ];
    
    for (const dockerPath of dockerPaths) {
      logger.info(`Docker í™˜ê²½ì—ì„œ ê²½ë¡œ í™•ì¸: ${dockerPath}`);
      if (fs.existsSync(dockerPath)) {
        logger.info(`CSV íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: ${dockerPath}`);
        return dockerPath;
      }
    }
  }
  
  // ì¼ë°˜ í™˜ê²½ ë˜ëŠ” Docker í™˜ê²½ì—ì„œ ì¶”ê°€ë¡œ ì‹œë„í•  ê²½ë¡œë“¤
  const possiblePaths = [
    join(path, 'dist', filename),
    join(path, filename),         // root ë””ë ‰í† ë¦¬
    join(path, 'src', filename),  // src ë””ë ‰í† ë¦¬
    join(__dirname, '..', '..', 'dist', filename),
    join(__dirname, '..', '..', filename),
    join(__dirname, '..', filename),
  ];

  // ëª¨ë“  ê²½ë¡œë¥¼ ë¡œê¹…í•˜ì—¬ ë””ë²„ê¹…
  possiblePaths.forEach(p => {
    logger.info(`ê²½ë¡œ í™•ì¸: ${p} (ì¡´ì¬: ${fs.existsSync(p)})`);
  });

  for (const filepath of possiblePaths) {
    if (fs.existsSync(filepath)) {
      logger.info(`CSV íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: ${filepath}`);
      return filepath;
    }
  }
  
  // ë§ˆì§€ë§‰ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ í•˜ë“œì½”ë”© ì‹œë„ (ê¸´ê¸‰ í´ë°±)
  const hardcodedPaths = [
    '/app/dist/IPB_250104_250305.csv',
    '/home/ubuntu/weather-api-backend/src/IPB_250104_250305.csv'
  ];
  
  for (const hardPath of hardcodedPaths) {
    logger.info(`í•˜ë“œì½”ë”© ê²½ë¡œ í™•ì¸: ${hardPath}`);
    if (fs.existsSync(hardPath)) {
      logger.info(`CSV íŒŒì¼ì„ í•˜ë“œì½”ë”© ê²½ë¡œì—ì„œ ì°¾ì•˜ìŠµë‹ˆë‹¤: ${hardPath}`);
      return hardPath;
    }
  }
  
  // íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì—ëŸ¬ ë°œìƒ
  logger.warn(`CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.`);
  throw new Error(`CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${filename}`);
}

/**
 * ë‚ ì§œ ë¬¸ìì—´ì„ íŒŒì‹±í•˜ëŠ” ê°•í™”ëœ í•¨ìˆ˜
 * ë‹¤ì–‘í•œ í˜•ì‹ê³¼ íŠ¹ìˆ˜ ê³µë°± ë¬¸ìë¥¼ ì²˜ë¦¬
 */
export function parseDate(dateStr: string): Date | null {
  // íŠ¹ìˆ˜ ê³µë°± ë¬¸ìë¥¼ í¬í•¨í•œ ëª¨ë“  ì¢…ë¥˜ì˜ ê³µë°± ì œê±° ë° í‘œì¤€ ê³µë°±ìœ¼ë¡œ ë³€í™˜
  const cleanDateStr = dateStr.replace(/[\s\u3000\u2000-\u200F\u2028-\u202F\u205F-\u206F]+/g, ' ').trim();
  
  // ê¸°ë³¸ Date íŒŒì‹± ì‹œë„
  const date = new Date(cleanDateStr);
  if (!isNaN(date.getTime())) {
    return date;
  }
  
  // ì‚¬ìš©ì ì •ì˜ í˜•ì‹ ì‹œë„ (ì˜ˆ: YYYY-MM-DDã…¤HH:MM:SS í˜•ì‹)
  const regex = /(\d{4}-\d{2}-\d{2})[^\d]+(\d{2}:\d{2}:\d{2})/;
  const match = regex.exec(dateStr);
  if (match) {
    const [, datePart, timePart] = match;
    const formattedStr = `${datePart}T${timePart}`;
    const parsedDate = new Date(formattedStr);
    if (!isNaN(parsedDate.getTime())) {
      return parsedDate;
    }
  }
  
  return null;
}

/**
 * CSV íŒŒì¼ì—ì„œ 1ë²ˆ ì„¼ì„œ ê·¸ë£¹ ë°ì´í„°ë¥¼ ì½ì–´ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
 */
export async function importWeatherDataFromCsv(csvFilePath: string, batchSize = 100): Promise<void> {
  const csvFileExists = fs.existsSync(csvFilePath);
  if (!csvFileExists) {
    throw new Error(`CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ${csvFilePath}`);
  }

  logger.info(`ğŸ”„ Starting CSV import from: ${csvFilePath}`);

  try {
    // CSV íŒŒì¼ ì½ê¸°
    const fileContent = fs.readFileSync(csvFilePath, 'utf8');
    logger.info(`CSV íŒŒì¼ í¬ê¸°: ${fileContent.length} ë°”ì´íŠ¸`);
    logger.info(`CSV íŒŒì¼ ì²˜ìŒ 100ì: ${fileContent.substring(0, 100)}`);

    // CSV íŒŒì‹±
    const parseResult = Papa.parse(fileContent, {
      header: true,
      skipEmptyLines: true,
      dynamicTyping: true, // ìë™ìœ¼ë¡œ ìˆ«ì íƒ€ì… ë³€í™˜
      transformHeader: (header: string) => header.trim(), // í—¤ë” ê³µë°± ì œê±°
      // í° íŒŒì¼ì„ ê³ ë ¤í•œ ì¶”ê°€ ì˜µì…˜
      delimiter: ",", // ëª…ì‹œì ìœ¼ë¡œ êµ¬ë¶„ì ì§€ì •
      delimitersToGuess: [',', '\t', '|', ';'], // ë‹¤ì–‘í•œ êµ¬ë¶„ì ì¶”ì¸¡
    });

    if (parseResult.errors && parseResult.errors.length > 0) {
      logger.error('CSV íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', parseResult.errors);
      throw new Error('CSV parsing failed');
    }

    const csvData = parseResult.data as any[];
    logger.info(`ğŸ“Š CSV ë°ì´í„° íŒŒì‹± ì™„ë£Œ: ${csvData.length}í–‰`);
    
    if (csvData.length === 0) {
      logger.warn('CSV íŒŒì¼ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.');
      return;
    }

    // CSV í—¤ë” ì •ë³´ ë¡œê¹…
    logger.info(`CSV í—¤ë”: ${JSON.stringify(parseResult.meta.fields)}`);
    // ì²« ë²ˆì§¸ í–‰ ë°ì´í„° ë¡œê¹…
    logger.info(`ì²« ë²ˆì§¸ í–‰ ë°ì´í„°: ${JSON.stringify(csvData[0])}`);

    // ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜
    const totalBatches = Math.ceil(csvData.length / batchSize);
    let processedRows = 0;
    let successCount = 0;
    let errorCount = 0;

    // ë°°ì¹˜ ì²˜ë¦¬
    for (let batchIndex = 0; batchIndex < totalBatches; batchIndex++) {
      const start = batchIndex * batchSize;
      const end = Math.min(start + batchSize, csvData.length);
      const batch = csvData.slice(start, end);

      const weatherBatch: WeatherCreationAttributes[] = [];

      // 1ë²ˆ ì„¼ì„œ ê·¸ë£¹ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ë³€í™˜
      for (const row of batch) {
        try {
          const timeStr = row.time;
          // ê°•í™”ëœ ë‚ ì§œ íŒŒì‹± í•¨ìˆ˜ ì‚¬ìš©
          const timeDate = parseDate(timeStr);
          
          if (!timeDate) {
            logger.warn(`Invalid date format in row: ${JSON.stringify(row)}`);
            errorCount++;
            continue;
          }

          // 1ë²ˆ ì„¼ì„œ ê·¸ë£¹ ë°ì´í„°ë§Œ ì¶”ì¶œ
          const weatherData: WeatherCreationAttributes = {
            time: timeDate,
            point: 1, // 1ë²ˆ ì„¼ì„œ ê·¸ë£¹
            airTemperature: row.Air_Temperature1,
            airHumidity: row.Air_Humidity1,
            airPressure: row.Air_Pressure1,
            soilTemperature: row.Soil_Temperature1,
            soilHumidity: row.Soil_Humidity1,
            soilEC: row.Soil_EC1,
            pyranometer: row.Pyranometer1,
            pasteTypeTemperature: row.Paste_type_temperature1,
          };

          // í•„ìˆ˜ í•„ë“œ ê²€ì¦
          const requiredFields = [
            'airTemperature',
            'airHumidity',
            'airPressure',
            'soilTemperature',
            'soilHumidity',
            'soilEC',
            'pyranometer',
          ];

          const isValid = requiredFields.every(
            (field) =>
              weatherData[field as keyof WeatherCreationAttributes] !== undefined &&
              weatherData[field as keyof WeatherCreationAttributes] !== null,
          );

          if (isValid) {
            weatherBatch.push(weatherData);
          } else {
            logger.warn(`Missing required fields in row: ${JSON.stringify(row)}`);
            errorCount++;
          }
        } catch (error) {
          logger.error(`Error processing row: ${JSON.stringify(row)}`, error);
          errorCount++;
        }
      }

      // ë°°ì¹˜ ì €ì¥
      try {
        if (weatherBatch.length > 0) {
          logger.info(`ë°°ì¹˜ ${batchIndex + 1}/${totalBatches}ì— ${weatherBatch.length}ê°œ ë°ì´í„° ì €ì¥ ì‹œë„`);
          await Weather.bulkCreate(weatherBatch);
          successCount += weatherBatch.length;
          logger.info(`ë°°ì¹˜ ${batchIndex + 1}/${totalBatches} ì €ì¥ ì„±ê³µ!`);
        } else {
          logger.warn(`ë°°ì¹˜ ${batchIndex + 1}/${totalBatches}ì— ì €ì¥í•  ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.`);
        }

        processedRows += batch.length;
        logger.info(`âœ… Processed batch ${batchIndex + 1}/${totalBatches} (${processedRows}/${csvData.length} rows)`);
      } catch (error) {
        logger.error(`Error saving batch ${batchIndex + 1}/${totalBatches}:`, error);
        errorCount += batch.length;
      }
    }

    logger.info(`ğŸ CSV import completed. Success: ${successCount}, Errors: ${errorCount}`);
  } catch (error) {
    logger.error(`CSV íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: ${error}`);
    throw error;
  }
}