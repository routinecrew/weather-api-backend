import { join } from 'path';
import { path } from 'app-root-path';
import fs from 'fs';
import Papa from 'papaparse';
import { configDotenv } from '../shared/configs/dotenv.config';
import { connectPostgres } from '../shared/configs/postgres.config';
import { Weather } from '../service-init/models/main/weather';
import { logger } from '../shared/configs/logger.config';
import { WeatherCreationAttributes } from '../service-init/models/main/weather';
import { Sequelize } from 'sequelize-typescript';

/**
 * CSV íŒŒì¼ì„ ì—¬ëŸ¬ ê²½ë¡œì—ì„œ ì°¾ëŠ” í•¨ìˆ˜
 */
function findCsvFile(filename: string): string {
  // ê°€ëŠ¥í•œ ê²½ë¡œë“¤ì„ ìˆœì„œëŒ€ë¡œ í™•ì¸
  const possiblePaths = [
    join(path, 'dist', filename),
    join(path, filename),         // root ë””ë ‰í† ë¦¬
    join(path, 'src', filename),  // src ë””ë ‰í† ë¦¬
    join('/', 'app', 'dist', filename),  // ë„ì»¤ ì»¨í…Œì´ë„ˆ ë‚´ dist ë””ë ‰í† ë¦¬
    join('/', 'app', filename),   // ë„ì»¤ ì»¨í…Œì´ë„ˆ ë‚´ root ë””ë ‰í† ë¦¬
  ];

  for (const filepath of possiblePaths) {
    if (fs.existsSync(filepath)) {
      logger.info(`CSV íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: ${filepath}`);
      return filepath;
    }
  }
  
  // íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ë¹ˆ ë¬¸ìì—´ ë°˜í™˜
  logger.warn(`CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.`);
  throw new Error(`CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${filename}`);
}

/**
 * CSV íŒŒì¼ì—ì„œ 1ë²ˆ ì„¼ì„œ ê·¸ë£¹ ë°ì´í„°ë¥¼ ì½ì–´ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
 */
async function importWeatherDataFromCsv(csvFilePath: string, batchSize = 100): Promise<void> {
  const csvFileExists = fs.existsSync(csvFilePath);
  if (!csvFileExists) {
    throw new Error(`CSV íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: ${csvFilePath}`);
  }

  logger.info(`ğŸ”„ Starting CSV import from: ${csvFilePath}`);

  // CSV íŒŒì¼ ì½ê¸°
  const fileContent = fs.readFileSync(csvFilePath, 'utf8');

  // CSV íŒŒì‹±
  const parseResult = Papa.parse(fileContent, {
    header: true,
    skipEmptyLines: true,
    dynamicTyping: true, // ìë™ìœ¼ë¡œ ìˆ«ì íƒ€ì… ë³€í™˜
    transformHeader: (header: string) => header.trim(), // í—¤ë” ê³µë°± ì œê±°
  });

  if (parseResult.errors && parseResult.errors.length > 0) {
    logger.error('CSV íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ:', parseResult.errors);
    throw new Error('CSV parsing failed');
  }

  const csvData = parseResult.data as any[];
  logger.info(`ğŸ“Š Total rows in CSV: ${csvData.length}`);

  // ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë³€ìˆ˜
  const totalBatches = Math.ceil(csvData.length / batchSize);
  let processedRows = 0;
  let successCount = 0;
  let errorCount = 0;

  // ë°°ì¹˜ ì²˜ë¦¬
  for (let batchIndex = 0; batchIndex < totalBatches; batchIndex++) {
    const start = batchIndex * batchSize;
    const end = Math.min(start + batchSize, csvData.length);
    const batch = csvData.slice(start, end);

    const weatherBatch: WeatherCreationAttributes[] = [];

    // 1ë²ˆ ì„¼ì„œ ê·¸ë£¹ ë°ì´í„°ë§Œ ì¶”ì¶œí•˜ì—¬ ë³€í™˜
    for (const row of batch) {
      try {
        const timeStr = row.time;
        // CSVì˜ time ë¬¸ìì—´ì´ ìœ íš¨í•œ ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸
        const timeDate = new Date(timeStr);

        if (isNaN(timeDate.getTime())) {
          logger.warn(`Invalid date format in row: ${JSON.stringify(row)}`);
          errorCount++;
          continue;
        }

        // 1ë²ˆ ì„¼ì„œ ê·¸ë£¹ ë°ì´í„°ë§Œ ì¶”ì¶œ
        const weatherData: WeatherCreationAttributes = {
          time: timeDate,
          point: 1, // 1ë²ˆ ì„¼ì„œ ê·¸ë£¹
          airTemperature: row.Air_Temperature1,
          airHumidity: row.Air_Humidity1,
          airPressure: row.Air_Pressure1,
          soilTemperature: row.Soil_Temperature1,
          soilHumidity: row.Soil_Humidity1,
          soilEC: row.Soil_EC1,
          pyranometer: row.Pyranometer1,
          pasteTypeTemperature: row.Paste_type_temperature1,
        };

        // í•„ìˆ˜ í•„ë“œ ê²€ì¦
        const requiredFields = [
          'airTemperature',
          'airHumidity',
          'airPressure',
          'soilTemperature',
          'soilHumidity',
          'soilEC',
          'pyranometer',
        ];

        const isValid = requiredFields.every(
          (field) =>
            weatherData[field as keyof WeatherCreationAttributes] !== undefined &&
            weatherData[field as keyof WeatherCreationAttributes] !== null,
        );

        if (isValid) {
          weatherBatch.push(weatherData);
        } else {
          logger.warn(`Missing required fields in row: ${JSON.stringify(row)}`);
          errorCount++;
        }
      } catch (error) {
        logger.error(`Error processing row: ${JSON.stringify(row)}`, error);
        errorCount++;
      }
    }

    // ë°°ì¹˜ ì €ì¥
    try {
      if (weatherBatch.length > 0) {
        await Weather.bulkCreate(weatherBatch);
        successCount += weatherBatch.length;
      }

      processedRows += batch.length;
      logger.info(`âœ… Processed batch ${batchIndex + 1}/${totalBatches} (${processedRows}/${csvData.length} rows)`);
    } catch (error) {
      logger.error(`Error saving batch ${batchIndex + 1}/${totalBatches}:`, error);
      errorCount += batch.length;
    }
  }

  logger.info(`ğŸ CSV import completed. Success: ${successCount}, Errors: ${errorCount}`);
}

async function main() {
  try {
    // í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    configDotenv();

    // CSV íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
    const csvFilename = 'IPB_250104_250305.csv';
    const csvFilePath = findCsvFile(csvFilename);

    // ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
    logger.info('ğŸ”Œ Connecting to database...');
    const seq = await connectPostgres();

    // CSV íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    await importWeatherDataFromCsv(csvFilePath);

    // ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
    await (seq as Sequelize).close();
    logger.info('ğŸ”Œ Database connection closed');
  } catch (error) {
    logger.error('âŒ Script execution failed:', error);
    process.exit(1);
  }
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
main()
  .then(() => {
    logger.info('âœ¨ Script completed successfully');
    process.exit(0);
  })
  .catch((error) => {
    logger.error('âŒ Unhandled error:', error);
    process.exit(1);
  });